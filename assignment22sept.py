# -*- coding: utf-8 -*-
"""Assignment3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12-Hr6KxlWzvhMsf3dcGocrWWNi41FucP
"""

import pandas as pd
import numpy as np
import seaborn as sn
import matplotlib.pyplot as py
!pip install kaggle

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Assuming the dataset is in the current directory, otherwise provide the full path
dataset_filename = "WA_Fn-UseC_-HR-Employee-Attrition.csv"
df = pd.read_csv(dataset_filename)

import pandas as pd

# Assuming you have already read the dataset into a DataFrame 'df'
# If not, please refer to the previous response for loading the dataset.

# Explore the dataset
print("Initial dataset shape:", df.shape)
print("Columns:", df.columns)

# Check for missing values
missing_values = df.isnull().sum()
print("Missing values:")
print(missing_values)

# Check for duplicate rows and remove them if necessary
df = df.drop_duplicates()
print("Dataset shape after removing duplicates:", df.shape)

# Explore the data types of columns
data_types = df.dtypes
print("Data types:")
print(data_types)

# Convert categorical variables to numerical using one-hot encoding
categorical_columns = ["BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "Over18", "OverTime"]
df = pd.get_dummies(df, columns=categorical_columns)

# Drop unnecessary columns, e.g., EmployeeNumber, EmployeeCount, StandardHours
columns_to_drop = ["EmployeeNumber", "EmployeeCount", "StandardHours"]
df = df.drop(columns_to_drop, axis=1)

# Perform feature scaling if necessary, e.g., for numerical columns like Age, MonthlyIncome, etc.
# You can use Min-Max scaling or Standardization as needed.

# Split the dataset into features (X) and target (y) using iloc
X = df.iloc[:, :-1]  # Select all columns except the last one (Attrition)
y = df.iloc[:, -1]   # Select only the last column (Attrition)

# Now, X contains the features, and y contains the target variable (Attrition)
# You can further split the data into training and testing sets or proceed with analysis or modeling.

X = df.drop("Attrition", axis=1)
y = df["Attrition"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Logistic Regression model
logreg_model = LogisticRegression(random_state=42)
logreg_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_logreg = logreg_model.predict(X_test)

# Evaluate the model
accuracy_logreg = accuracy_score(y_test, y_pred_logreg)
print("Logistic Regression Accuracy:", accuracy_logreg)

# Generate a classification report
report_logreg = classification_report(y_test, y_pred_logreg)
print("Logistic Regression Classification Report:\n", report_logreg)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Assuming you have already loaded and preprocessed the dataset as shown earlier

# Perform one-hot encoding for categorical variables
X_encoded = pd.get_dummies(X, drop_first=True)

# Split the data into training and testing sets (e.g., 80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Model 1: Logistic Regression
logistic_model = LogisticRegression(random_state=42)
logistic_model.fit(X_train, y_train)
logistic_predictions = logistic_model.predict(X_test)

# Calculate performance metrics for Logistic Regression
logistic_accuracy = accuracy_score(y_test, logistic_predictions)
logistic_classification_report = classification_report(y_test, logistic_predictions)
logistic_confusion_matrix = confusion_matrix(y_test, logistic_predictions)

# Model 2: Decision Tree Classifier
decision_tree_model = DecisionTreeClassifier(random_state=42)
decision_tree_model.fit(X_train, y_train)
decision_tree_predictions = decision_tree_model.predict(X_test)

# Calculate performance metrics for Decision Tree Classifier
decision_tree_accuracy = accuracy_score(y_test, decision_tree_predictions)
decision_tree_classification_report = classification_report(y_test, decision_tree_predictions)
decision_tree_confusion_matrix = confusion_matrix(y_test, decision_tree_predictions)

# Print performance metrics
print("Logistic Regression Performance Metrics:")
print("Accuracy:", logistic_accuracy)
print("Classification Report:\n", logistic_classification_report)
print("Confusion Matrix:\n", logistic_confusion_matrix)

print("\nDecision Tree Classifier Performance Metrics:")
print("Accuracy:", decision_tree_accuracy)
print("Classification Report:\n", decision_tree_classification_report)
print("Confusion Matrix:\n", decision_tree_confusion_matrix)

